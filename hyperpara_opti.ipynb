{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fc6bc049",
      "metadata": {
        "id": "fc6bc049"
      },
      "source": [
        "# Modify this variable to adapt to your storage in you're cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b2a8b604",
      "metadata": {
        "id": "b2a8b604"
      },
      "outputs": [],
      "source": [
        "# project location in Google drive\n",
        "project_location_drive = '/content/drive/MyDrive/Fac/Master/CV'\n",
        "project_location_local = '/content/'\n",
        "\n",
        "#\n",
        "data_location_local = \"/content/data/media/nas/01_Datasets/CT/LITS/\"\n",
        "\n",
        "# data_location_local = \"data_skip/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "WXyO_7kdgF32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXyO_7kdgF32",
        "outputId": "632889b0-3f46-4549-8026-905f442dd10f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.18.1)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1r19xtcbAxkS",
      "metadata": {
        "id": "1r19xtcbAxkS"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fkbQoHwhNIFk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkbQoHwhNIFk",
        "outputId": "d7e67295-a255-478d-8fe2-35608a249416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtpoux\u001b[0m (\u001b[33mtumor-3D\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "! wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2P4kwQLbRy0P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P4kwQLbRy0P",
        "outputId": "d54302e7-3bab-4e9d-ab40-0f04e4ddc30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a6ae077f",
      "metadata": {
        "id": "a6ae077f"
      },
      "outputs": [],
      "source": [
        "! ln -s /content/drive/MyDrive/Fac/Master/optuna /content/optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u67EjurQBwxy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u67EjurQBwxy",
        "outputId": "4270988b-c19f-4ab2-8a71-66e289e654f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/Fac/Master/CV/checkpoints' -> '/content/checkpoints'\n",
            "'/content/drive/MyDrive/Fac/Master/CV/checkpoints/run_continued_last.pth' -> '/content/checkpoints/run_continued_last.pth'\n",
            "'/content/drive/MyDrive/Fac/Master/CV/checkpoints/run_continued_best.pth' -> '/content/checkpoints/run_continued_best.pth'\n",
            "'/content/drive/MyDrive/Fac/Master/CV/checkpoints/checkpoint_last.pth' -> '/content/checkpoints/checkpoint_last.pth'\n",
            "'/content/drive/MyDrive/Fac/Master/CV/checkpoints/checkpoint_best.pth' -> '/content/checkpoints/checkpoint_best.pth'\n",
            "'/content/drive/MyDrive/Fac/Master/CV/data' -> '/content/data'\n",
            "'/content/drive/MyDrive/Fac/Master/CV/data/Training_Batch2.zip' -> '/content/data/Training_Batch2.zip'\n",
            "'/content/drive/MyDrive/Fac/Master/CV/data/Training_Batch1.zip' -> '/content/data/Training_Batch1.zip'\n"
          ]
        }
      ],
      "source": [
        "# copy all the folder so the data leave on the same host has the GPU used\n",
        "! cp -rv /content/drive/MyDrive/Fac/Master/CV/* /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pgIH7hasB6qY",
      "metadata": {
        "collapsed": true,
        "id": "pgIH7hasB6qY"
      },
      "outputs": [],
      "source": [
        "# unzip dataset in //\n",
        "!unzip /content/data/Training_Batch1.zip -d /content/data/ & \\\n",
        " unzip /content/data/Training_Batch2.zip -d /content/data/ & \\\n",
        " wait"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61inx0_faf0J",
      "metadata": {
        "id": "61inx0_faf0J"
      },
      "outputs": [],
      "source": [
        "! rm -r  /content/data/Training_Batch1.zip\n",
        "! rm -r  /content/data/Training_Batch2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae595640",
      "metadata": {
        "id": "ae595640"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n",
        "from dataset.LiTSPatchDataset import *\n",
        "from utility.dice_score import dice_loss_fg, dice_eval\n",
        "from utility.log_image import log_images_wandb\n",
        "from tqdm import tqdm\n",
        "from torch import sigmoid\n",
        "from torch.amp import autocast, GradScaler\n",
        "from UNet.unet_model import UNet\n",
        "import os, re\n",
        "import gc\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w7p2w8HTI0tz",
      "metadata": {
        "id": "w7p2w8HTI0tz"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a673607d",
      "metadata": {
        "id": "a673607d"
      },
      "outputs": [],
      "source": [
        "def build_pairs(*batch_dirs):\n",
        "    pairs = []\n",
        "    for d in batch_dirs:\n",
        "        files = os.listdir(d)\n",
        "\n",
        "        seg_files = [f for f in files if \"segmentation\" in f]\n",
        "        for seg in sorted(seg_files):\n",
        "            m = re.search(r\"segmentation-(\\d+)\", seg)\n",
        "            if not m:\n",
        "                continue\n",
        "            idx = m.group(1)\n",
        "\n",
        "\n",
        "            vol_candidates = [\n",
        "                f\"volume-{idx}.nii\",\n",
        "            ]\n",
        "            vol = next((v for v in vol_candidates if v in files), None)\n",
        "            if vol is None:\n",
        "                raise FileNotFoundError(f\"Volume manquant pour {seg} dans {d}\")\n",
        "\n",
        "            pairs.append((os.path.join(d, vol), os.path.join(d, seg)))\n",
        "    return pairs\n",
        "\n",
        "\n",
        "pairs = build_pairs(os.path.join(data_location_local ,\"Training Batch 1/\"), os.path.join(data_location_local ,\"Training Batch 2/\"))\n",
        "print(\"Nb paires:\", len(pairs))\n",
        "print(pairs[0])\n",
        "\n",
        "\n",
        "X_paths = [p[0] for p in pairs]\n",
        "y_paths = [p[1] for p in pairs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YiIb8MmLdvAj",
      "metadata": {
        "id": "YiIb8MmLdvAj"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ba31fc8",
      "metadata": {
        "id": "3ba31fc8"
      },
      "outputs": [],
      "source": [
        "def split_patients(patient_ids, train=0.8, val=0.15, test=0.05, seed=42):\n",
        "    assert abs(train + val + test - 1.0) < 1e-9\n",
        "    ids = list(patient_ids)\n",
        "    random.Random(seed).shuffle(ids)\n",
        "\n",
        "    n = len(ids)\n",
        "    n_train = int(train * n)\n",
        "    n_val = int(val * n)\n",
        "\n",
        "    train_ids = ids[:n_train]\n",
        "    val_ids   = ids[n_train:n_train+n_val]\n",
        "    test_ids  = ids[n_train+n_val:]\n",
        "    return train_ids, val_ids, test_ids\n",
        "\n",
        "def make_paths(batch_dirs, patient_ids):\n",
        "    X, Y = [], []\n",
        "    for pid in patient_ids:\n",
        "        for d in batch_dirs:\n",
        "            vol = os.path.join(d, f\"volume-{pid}.nii\")\n",
        "            seg = os.path.join(d, f\"segmentation-{pid}.nii\")\n",
        "            if os.path.exists(vol) and os.path.exists(seg):\n",
        "                X.append(vol); Y.append(seg)\n",
        "                break\n",
        "    return X, Y\n",
        "\n",
        "max_in_paths = 0\n",
        "for d in [os.path.join(data_location_local ,\"Training Batch 1/\"), os.path.join(data_location_local ,\"Training Batch 2/\")]:\n",
        "        files = os.listdir(d)\n",
        "\n",
        "        seg_files = [f for f in files if \"volume\" in f]\n",
        "        for seg in sorted(seg_files):\n",
        "            m = re.search(r\"volume-(\\d+)\", seg)\n",
        "            if not m:\n",
        "                continue\n",
        "            if int(m[1]) > max_in_paths:\n",
        "                 max_in_paths = int(m[1])\n",
        "            else:\n",
        "                 continue\n",
        "\n",
        "patient_ids = np.arange(max_in_paths+1)\n",
        "\n",
        "train_ids, val_ids, test_ids = split_patients(patient_ids)\n",
        "\n",
        "\n",
        "\n",
        "X_train_paths, y_train_paths  = make_paths([os.path.join(data_location_local ,\"Training Batch 1/\"), os.path.join(data_location_local ,\"Training Batch 2/\")], train_ids)\n",
        "X_val_paths, y_val_paths= make_paths([os.path.join(data_location_local ,\"Training Batch 1/\"), os.path.join(data_location_local ,\"Training Batch 2/\")], val_ids)\n",
        "X_test_paths, y_test_paths= make_paths([os.path.join(data_location_local ,\"Training Batch 1/\"), os.path.join(data_location_local ,\"Training Batch 2/\")], test_ids)\n",
        "train_dataset = LiTSPatchDataset(X_train_paths,y_train_paths)\n",
        "val_dataset = LiTSPatchDataset(X_val_paths,y_val_paths)\n",
        "test_dataset = LiTSPatchDataset(X_test_paths,y_test_paths)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1b55821",
      "metadata": {
        "id": "c1b55821"
      },
      "outputs": [],
      "source": [
        "def flush_memory():\n",
        "    # force le Garbage Collector de Python\n",
        "    gc.collect()\n",
        "    # vide le cache CUDA\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ddf252",
      "metadata": {
        "id": "32ddf252"
      },
      "outputs": [],
      "source": [
        "def unet_train(\n",
        "    model,\n",
        "    train_dataset,\n",
        "    val_dataset,\n",
        "    device,\n",
        "    epochs: int = 10,\n",
        "    batch_size: int = 1,\n",
        "    l_rate: float = 1e-4,\n",
        "    save_checkpoints: bool = True,\n",
        "    weight_decay: float = 1e-5,\n",
        "    patience: int = 7,\n",
        "    min_delta: float = 0.005,\n",
        "    run_name: str = \"run\",\n",
        "    early_stop: bool = True,\n",
        "    trial=None\n",
        "):\n",
        "\n",
        "\n",
        "    use_amp = (device.type == \"cuda\")\n",
        "    scaler = GradScaler(\"cuda\", enabled=use_amp)\n",
        "\n",
        "    loader_args = dict(batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=loader_args[\"batch_size\"],\n",
        "        num_workers=loader_args[\"num_workers\"],\n",
        "        pin_memory=loader_args[\"pin_memory\"],\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=loader_args[\"batch_size\"],\n",
        "        num_workers=loader_args[\"num_workers\"],\n",
        "        pin_memory=loader_args[\"pin_memory\"],\n",
        "        shuffle=False,\n",
        "        drop_last=False\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=l_rate,\n",
        "        betas=(0.9, 0.999),\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    pos_weight = torch.tensor([25.0], device=device)\n",
        "    bce_loss = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "\n",
        "    val_mri_idx = [0,1,2,3,4,5]\n",
        "\n",
        "\n",
        "    viz_subset = Subset(val_dataset, val_mri_idx)\n",
        "\n",
        "    losses_train, losses_val, dices_val = [], [], []\n",
        "\n",
        "    best_dice = -1.0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        cum_loss = 0.0\n",
        "        nb_batches = 0\n",
        "\n",
        "        for x_batch, y_batch in tqdm(train_loader, desc=f\"Train epoch {epoch}\", leave=False):\n",
        "            x = x_batch.to(device)\n",
        "            y = y_batch.to(device)\n",
        "\n",
        "            if y.dim() == 3:\n",
        "                y = y.unsqueeze(1)\n",
        "            y = y.float()\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            with autocast(enabled=use_amp, device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "                logits = model(x)\n",
        "                loss = dice_loss_fg(logits, y) + bce_loss(logits, y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            cum_loss += float(loss.item())\n",
        "            nb_batches += 1\n",
        "            wandb.log({\"loss_train\": float(loss.item())})\n",
        "\n",
        "\n",
        "        loss_epoch = cum_loss / nb_batches if nb_batches > 0 else float(\"nan\")\n",
        "\n",
        "        wandb.log({\"epoch\": epoch, \"loss_train\": loss_epoch})\n",
        "\n",
        "        model.eval()\n",
        "        cum_loss_val = 0.0\n",
        "        nb_val_batches = 0\n",
        "        dice_sum = 0.0\n",
        "        n_sum = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in tqdm(val_loader, desc=f\"Val epoch {epoch}\", leave=False):\n",
        "                x = x_batch.to(device)\n",
        "                y = y_batch.to(device)\n",
        "\n",
        "                if y.dim() == 3:\n",
        "                    y = y.unsqueeze(1)\n",
        "                y = y.float()\n",
        "\n",
        "                with autocast(enabled=use_amp, device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "                    logits = model(x)\n",
        "                    batch_loss_val = dice_loss_fg(logits, y) + bce_loss(logits, y)\n",
        "\n",
        "                dice_batch, n_valid = dice_eval(logits, y)\n",
        "                dice_sum += float(dice_batch) * int(n_valid)\n",
        "                n_sum += int(n_valid)\n",
        "\n",
        "                cum_loss_val += float(batch_loss_val.item())\n",
        "                nb_val_batches += 1\n",
        "\n",
        "        dice_epoch = (dice_sum / n_sum) if n_sum > 0 else float(\"nan\")\n",
        "        loss_val_epoch = (cum_loss_val / nb_val_batches) if nb_val_batches > 0 else float(\"nan\")\n",
        "\n",
        "        losses_train.append(loss_epoch)\n",
        "        losses_val.append(loss_val_epoch)\n",
        "        dices_val.append(dice_epoch)\n",
        "\n",
        "        wandb.log({\"epoch\": epoch, \"loss_val\": loss_val_epoch, \"dice_val\": dice_epoch})\n",
        "\n",
        "\n",
        "\n",
        "        if epoch % 2 == 0:\n",
        "            log_images_wandb(model,\n",
        "                            val_dataset,\n",
        "                            device,\n",
        "                            indices=val_mri_idx,\n",
        "                            epoch=epoch,\n",
        "                            threshold=0.5,\n",
        "                            alpha=0.45)\n",
        "\n",
        "\n",
        "        if save_checkpoints:\n",
        "            ckpt = {\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"best_dice\": best_dice,\n",
        "                \"loss_train\": losses_train,\n",
        "                \"loss_val\": losses_val,\n",
        "                \"dice_val\": dices_val,\n",
        "            }\n",
        "            torch.save(ckpt, f\"{run_name}_last.pth\")\n",
        "\n",
        "        if trial is not None:\n",
        "            trial.report(dice_epoch, epoch)\n",
        "\n",
        "            # Check if the trial should be pruned (stopped early)\n",
        "            if trial.should_prune():\n",
        "                raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        if early_stop:\n",
        "\n",
        "            if not np.isnan(dice_epoch) and dice_epoch > best_dice + min_delta:\n",
        "                best_dice = dice_epoch\n",
        "                epochs_no_improve = 0\n",
        "\n",
        "                if save_checkpoints:\n",
        "                    ckpt[\"best_dice\"] = best_dice\n",
        "                    torch.save(ckpt, f\"{run_name}_best.pth\")\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch}!\")\n",
        "                break\n",
        "\n",
        "    artifact = wandb.Artifact('Unet', type='model')\n",
        "    if os.path.exists(f\"{run_name}_best.pth\"):\n",
        "        artifact.add_file(f\"{run_name}_best.pth\")\n",
        "    else :\n",
        "        artifact.add_file(f\"{run_name}_last.pth\")\n",
        "    wandb.log_artifact(artifact)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return losses_train, losses_val, dices_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "febaa638",
      "metadata": {
        "id": "febaa638"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    if device.type == \"cuda\":\n",
        "        flush_memory() # clear memory before starting a new trial, we can't afford to crash because of out-of-memory ;)\n",
        "\n",
        "    # hyper parameters to optimize\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3, step=0.1)\n",
        "    l_rate = trial.suggest_float(\"l_rate\", 1e-5, 1e-3, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
        "    bilinear = trial.suggest_categorical(\"bilinear\", [True, False])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    hyperparameters = {\n",
        "        \"dropout\": dropout,\n",
        "        \"l_rate\": l_rate,\n",
        "        \"weight_decay\": weight_decay,\n",
        "        \"bilinear\": bilinear,\n",
        "        \"max_epochs\": 120,\n",
        "        \"patience\": 10,\n",
        "        \"min_delta\": 0.001,\n",
        "        \"batch_size\": 32,\n",
        "        \"early_stop\": True\n",
        "    }\n",
        "\n",
        "\n",
        "    model = UNet(n_channels=1, n_classes=1, bilinear=hyperparameters[\"bilinear\"], dropout=hyperparameters[\"dropout\"]).to(device)\n",
        "\n",
        "    # parameters logging\n",
        "    project_name = \"tumor-3D\"\n",
        "    group_name = \"optuna-study-1\"\n",
        "\n",
        "    wandb.init(project=project_name, config=hyperparameters, name=f\"trial-{trial.number}\", group=group_name)\n",
        "\n",
        "    print(f\"Starting trial {trial.number} with parameters: {[dropout, l_rate, weight_decay, bilinear]}\")\n",
        "    try :\n",
        "        _, _, dices_val = unet_train(\n",
        "            model,\n",
        "            train_dataset,\n",
        "            val_dataset,\n",
        "            device,\n",
        "            epochs=hyperparameters[\"max_epochs\"],\n",
        "            batch_size=hyperparameters[\"batch_size\"],\n",
        "            l_rate=hyperparameters[\"l_rate\"],\n",
        "            weight_decay=hyperparameters[\"weight_decay\"],\n",
        "            patience=hyperparameters[\"patience\"],\n",
        "            min_delta=hyperparameters[\"min_delta\"],\n",
        "            early_stop=hyperparameters[\"early_stop\"],\n",
        "            trial=trial,\n",
        "            run_name=f\"trial-{trial.number}\"\n",
        "        )\n",
        "\n",
        "    except optuna.exceptions.TrialPruned:\n",
        "        wandb.finish()\n",
        "        print(f\"Trial {trial.number} pruned.\")\n",
        "        return 0.0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Trial {trial.number} failed with exception: {e}\")\n",
        "        wandb.finish()\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "\n",
        "    best_dice = np.max(dices_val) if len(dices_val) > 0 else 0.0\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "    print(f\"Trial {trial.number} completed with best dice: {best_dice}\")\n",
        "\n",
        "    return best_dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "754e20ec",
      "metadata": {
        "id": "754e20ec"
      },
      "outputs": [],
      "source": [
        "def create_conf_study():\n",
        "    \"\"\"\n",
        "    Create a configuration for Optuna.\n",
        "    \"\"\"\n",
        "\n",
        "    storage = f\"sqlite:///optuna/optuna_study__{\"optuna-study-1\"}.db\"\n",
        "    sampler = optuna.samplers.TPESampler()\n",
        "    pruner = optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=5, interval_steps=3)\n",
        "\n",
        "    return storage, sampler, pruner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c26b1c7",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7c26b1c7"
      },
      "outputs": [],
      "source": [
        "# create study db if needed\n",
        "\n",
        "storage, sampler, pruner = create_conf_study()\n",
        "\n",
        "study = optuna.create_study( direction=\"maximize\", study_name=\"optuna-study-1\", storage=storage, sampler=sampler, pruner=pruner, load_if_exists=True)\n",
        "\n",
        "\n",
        "\n",
        "# launch optimization\n",
        "study.optimize(objective, n_trials=100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}